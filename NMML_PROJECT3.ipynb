{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONJ2TQUsGQjzzEB73hY+Qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IRPARKS/NMML/blob/main/NMML_PROJECT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rat08-20130711_017.h5"
      ],
      "metadata": {
        "id": "ES3dmdiHandl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "filepath = 'Rat08-20130711_017.h5'  # data file\n",
        "f = h5py.File(filepath, 'r')  # read data with h5 format\n",
        "fs = f.attrs['fs'][0]  # get sampling frequency of LFP signal (Hz)\n",
        "print(\"Sampling rate: %.1f Hz\" % (fs))"
      ],
      "metadata": {
        "id": "-9WRFD6watqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = []  # two states (NREM & WAKE) to be classified\n",
        "# LFP recordings are store in two h5 groups for each state\n",
        "# Under each h5 group, the LFP recordings are divided into several segments with different lengths.\n",
        "for name, grp in f.items():\n",
        "  states.append(name)\n",
        "  print(\"State: %s\" % (name))\n",
        "  print(\"Segment IDs:\")\n",
        "  print(list(grp.keys()))"
      ],
      "metadata": {
        "id": "ZOIlPd1haw9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the recording in to numpy arrays\n",
        "# Use a dictionary to store the LFP recordings of the two states\n",
        "# each containing a list of numpy arrays of all segments\n",
        "lfp = {key: [] for key in states}\n",
        "for key in states:\n",
        "  group = f[key]  # h5 group of a state\n",
        "  n = len(group)  # number of segments\n",
        "  for i in range(n):\n",
        "    lfp[key].append(group[str(i+1)][()].astype(float))  # convert data to numpy array and from int type to float type\n",
        "\n",
        "# print(lfp)"
      ],
      "metadata": {
        "id": "gfbjGWsba0ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = lfp['NREM'][10]  # accessing the 10-th LFP segment in NREM state\n",
        "t = np.arange(x.size)/fs  # time points\n",
        "\n",
        "plt.plot(t,x)\n",
        "plt.xlabel('second')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0ESG_2LBa1Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define parameters\n",
        "clip_length = 5  # Length of each clip in seconds\n",
        "clip_length_samples = int(clip_length * fs)  # Convert clip length to samples\n",
        "\n",
        "# Initialize lists to store clips and labels\n",
        "clips = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each state\n",
        "for state in lfp.keys():\n",
        "    for segment in lfp[state]:\n",
        "        # Calculate the number of clips in the segment\n",
        "        num_clips = len(segment) // clip_length_samples\n",
        "\n",
        "        # Cut the segment into smaller clips\n",
        "        for i in range(num_clips):\n",
        "            start_index = i * clip_length_samples\n",
        "            end_index = start_index + clip_length_samples\n",
        "            clip = segment[start_index:end_index]\n",
        "\n",
        "            # Append the clip and its corresponding label to the lists\n",
        "            clips.append(clip)\n",
        "            labels.append(state)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "clips = np.array(clips)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Print the shape of the resulting arrays\n",
        "print(\"Shape of clips array:\", clips.shape)\n",
        "print(\"Shape of labels array:\", labels.shape)\n"
      ],
      "metadata": {
        "id": "aDGj2jcQa2wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d-PWfv4XbIfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}