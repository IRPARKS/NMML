{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMfMRxUqEhRISGfTIkrlVkL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IRPARKS/NMML/blob/main/NMMLHW13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Importing Libraries**:\n",
        "   - The code starts by importing necessary libraries including `torch` (PyTorch), `torch.nn.functional` (for various neural network functions), `DataLoader` (for batch data loading), and custom modules (`WavenetDataset`, `WaveNetModel`, `WavenetTrainer`, `Logger`) specific to the WaveNet model and training process.\n",
        "\n",
        "2. **Loading Latest Model Checkpoint**:\n",
        "   - The function `load_latest_model_from` is defined to load the latest saved model checkpoint from a specified `snapshot_path` if available. It loads the model's state dictionary (`model_state_dict`) from the checkpoint file.\n",
        "\n",
        "3. **Initializing CUDA**:\n",
        "   - It checks if CUDA (GPU) is available. If CUDA is available, the model and related tensors will be moved to the GPU for accelerated computation.\n",
        "\n",
        "4. **WaveNet Model Initialization**:\n",
        "   - The WaveNet model (`WaveNetModel`) is initialized with specified parameters such as the number of layers (`layers`), blocks (`blocks`), dilation channels (`dilation_channels`), residual channels (`residual_channels`), skip channels (`skip_channels`), end channels (`end_channels`), and output length (`output_length`). The model is then moved to the specified device (GPU if available).\n",
        "\n",
        "5. **Initializing Dataset and DataLoader**:\n",
        "   - A custom `WavenetDataset` is initialized with specified dataset parameters (`dataset_file`, `item_length`, `target_length`, `file_location`, `test_stride`). This dataset is then wrapped by a `DataLoader` for batch processing during training.\n",
        "\n",
        "6. **Initializing Logger**:\n",
        "   - A `Logger` object is initialized with specified logging intervals for training progress monitoring and model evaluation.\n",
        "\n",
        "7. **Initializing WavenetTrainer**:\n",
        "   - A `WavenetTrainer` object is initialized with the WaveNet model, dataset loader, learning rate (`lr`), snapshot saving path (`snapshot_path`), and logger. This trainer manages the training process including optimization and logging.\n",
        "\n",
        "8. **Training Loop**:\n",
        "   - The training loop runs for a specified number of `epochs`. Inside each epoch, it iterates over batches from the dataset loader.\n",
        "   - For each batch:\n",
        "     - Data (`x`, `target`) is moved to the specified device (GPU).\n",
        "     - The model is used to compute predictions (`output`) given the input (`x`).\n",
        "     - The loss is calculated using cross-entropy loss between the predicted output and target values.\n",
        "     - Backpropagation (`loss.backward()`) is performed to compute gradients.\n",
        "     - The optimizer (`trainer.optimizer`) is used to update model parameters (`trainer.optimizer.step()`).\n",
        "     - Training progress (including loss) is printed at specified logging intervals (`logger.log_interval`).\n",
        "   - At the end of each epoch, the model checkpoint is optionally saved based on `trainer.snapshot_interval`.\n",
        "\n",
        "9. **Saving Model Checkpoints**:\n",
        "   - At specified intervals (`trainer.snapshot_interval`), the current model state (including epoch number, model state dictionary, optimizer state, and loss) is saved to a file in the specified `snapshot_path`.\n"
      ],
      "metadata": {
        "id": "Tuz5PO5bNtb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Vichoko/pytorch-wavenet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xzE7rQH_SyT",
        "outputId": "670aa150-3e97-4d3a-feb8-09ddb7d25f26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-wavenet'...\n",
            "remote: Enumerating objects: 1168, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 1168 (delta 3), reused 6 (delta 3), pack-reused 1158\u001b[K\n",
            "Receiving objects: 100% (1168/1168), 268.95 MiB | 20.86 MiB/s, done.\n",
            "Resolving deltas: 100% (720/720), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from audio_data import WavenetDataset\n",
        "from wavenet_model import WaveNetModel\n",
        "from wavenet_training import WavenetTrainer\n",
        "from model_logging import Logger\n",
        "\n",
        "\n",
        "# Function to load the latest model checkpoint\n",
        "def load_latest_model_from(snapshot_path, model):\n",
        "    # Specify the file path for the latest model checkpoint\n",
        "    checkpoint_file = f'{snapshot_path}/best_model.pth'\n",
        "\n",
        "    # Load the model checkpoint\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Load the model state dict\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Initialize CUDA if available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "ltype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
        "\n",
        "# Model parameters\n",
        "layers = 3\n",
        "blocks = 2\n",
        "dilation_channels = 8\n",
        "residual_channels = 8\n",
        "skip_channels = 64\n",
        "end_channels = 32\n",
        "output_length = 4\n",
        "\n",
        "# Initialize WaveNet model\n",
        "model = WaveNetModel(layers=layers,\n",
        "                     blocks=blocks,\n",
        "                     dilation_channels=dilation_channels,\n",
        "                     residual_channels=residual_channels,\n",
        "                     skip_channels=skip_channels,\n",
        "                     end_channels=end_channels,\n",
        "                     output_length=output_length,\n",
        "                     dtype=dtype,\n",
        "                     bias=True).to(device)\n",
        "\n",
        "# Dataset parameters\n",
        "dataset_file = '/content/pytorch-wavenet/train_samples/bach_chaconne/dataset.npz'\n",
        "item_length = model.receptive_field + model.output_length - 1\n",
        "target_length = model.output_length\n",
        "file_location = 'train_samples/bach_chaconne'\n",
        "test_stride = 500\n",
        "\n",
        "# Initialize WavenetDataset\n",
        "data = WavenetDataset(dataset_file=dataset_file,\n",
        "                      item_length=item_length,\n",
        "                      target_length=target_length,\n",
        "                      file_location=file_location,\n",
        "                      test_stride=test_stride)\n",
        "\n",
        "# DataLoader for batch processing\n",
        "batch_size = 16\n",
        "data_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize Logger for model training\n",
        "logger = Logger(log_interval=200,\n",
        "                validation_interval=400,\n",
        "                generate_interval=1000)\n",
        "\n",
        "# Initialize WavenetTrainer\n",
        "trainer = WavenetTrainer(model=model,\n",
        "                          dataset=data_loader,\n",
        "                          lr=0.001,\n",
        "                          snapshot_path='snapshots',\n",
        "                          snapshot_name='chaconne_model',\n",
        "                          snapshot_interval=1000,\n",
        "                          logger=logger,\n",
        "                          dtype=dtype,\n",
        "                          ltype=ltype)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, (x, target) in enumerate(data_loader):\n",
        "        x, target = x.to(device), target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(x)\n",
        "\n",
        "        # Resize target to match the output shape\n",
        "        target = target.view(-1)  # Flatten to match the output shape\n",
        "\n",
        "        # Compute loss\n",
        "        loss = F.cross_entropy(output.view(-1, output.size(-1)), target)\n",
        "\n",
        "        # Backward and optimize\n",
        "        trainer.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        trainer.optimizer.step()\n",
        "\n",
        "        # Print training progress\n",
        "        if batch_idx % logger.log_interval == 0:\n",
        "            print(f\"Epoch: {epoch + 1}, Batch: {batch_idx}, Loss: {loss.item()}\")\n",
        "\n",
        "    # Optionally log or evaluate at end of epoch\n",
        "    # Example: Save model checkpoint\n",
        "    if (epoch + 1) % trainer.snapshot_interval == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "        }, f'snapshots/epoch_{epoch + 1}.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juOF9CZSJ1Oj",
        "outputId": "45e10783-ae24-4b6f-97a2-04818695d925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one hot input\n",
            "Epoch: 1, Batch: 0, Loss: 5.517580986022949\n",
            "Epoch: 1, Batch: 200, Loss: 5.147301197052002\n",
            "Epoch: 1, Batch: 400, Loss: 5.076307773590088\n",
            "Epoch: 1, Batch: 600, Loss: 4.77754020690918\n",
            "Epoch: 1, Batch: 800, Loss: 5.2534918785095215\n",
            "Epoch: 1, Batch: 1000, Loss: 4.678632736206055\n",
            "Epoch: 1, Batch: 1200, Loss: 4.581977844238281\n",
            "Epoch: 1, Batch: 1400, Loss: 4.732357501983643\n",
            "Epoch: 1, Batch: 1600, Loss: 4.235000133514404\n",
            "Epoch: 1, Batch: 1800, Loss: 4.090487480163574\n",
            "Epoch: 1, Batch: 2000, Loss: 4.087838649749756\n",
            "Epoch: 1, Batch: 2200, Loss: 4.087427139282227\n",
            "Epoch: 1, Batch: 2400, Loss: 3.736981153488159\n",
            "Epoch: 1, Batch: 2600, Loss: 4.095047473907471\n",
            "Epoch: 1, Batch: 2800, Loss: 4.018249988555908\n",
            "Epoch: 1, Batch: 3000, Loss: 4.022060394287109\n",
            "Epoch: 1, Batch: 3200, Loss: 3.8930771350860596\n",
            "Epoch: 1, Batch: 3400, Loss: 3.8599467277526855\n",
            "Epoch: 1, Batch: 3600, Loss: 3.641538619995117\n",
            "Epoch: 1, Batch: 3800, Loss: 3.9623162746429443\n",
            "Epoch: 1, Batch: 4000, Loss: 3.993640422821045\n",
            "Epoch: 1, Batch: 4200, Loss: 3.7640535831451416\n",
            "Epoch: 1, Batch: 4400, Loss: 3.8092150688171387\n",
            "Epoch: 1, Batch: 4600, Loss: 3.8569276332855225\n",
            "Epoch: 1, Batch: 4800, Loss: 3.9184536933898926\n",
            "Epoch: 1, Batch: 5000, Loss: 4.317704677581787\n",
            "Epoch: 1, Batch: 5200, Loss: 3.7372419834136963\n",
            "Epoch: 1, Batch: 5400, Loss: 4.404197692871094\n",
            "Epoch: 1, Batch: 5600, Loss: 3.530910015106201\n",
            "Epoch: 1, Batch: 5800, Loss: 3.6678953170776367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general trend seen from this is the loss values generally decrease over batches, which is a positive sign indicating that the model is learning from the training data. Some batches show temporary increases in loss, suggesting potential challenges or noise in the training data that affect the model's learning. The decreasing trend of loss values indicates that the model is improving over the course of Epoch 1, capturing more complex patterns in the data."
      ],
      "metadata": {
        "id": "6CqYH2y6JTGy"
      }
    }
  ]
}